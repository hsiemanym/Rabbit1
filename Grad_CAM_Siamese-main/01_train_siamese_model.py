# -*- coding: utf-8 -*-
"""01.Train_Siamese_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JiBizsQM1m1L0JEftb5J116p83ph4VpC
"""
# 데이터 불러오기, 모델 초기화, 학습 반복, 검증 과정을 모두 통합하여 실행

import warnings
warnings.filterwarnings("ignore")

import os
import random
import numpy as np
import yaml
import time
from tqdm import tqdm

import torch
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

from utils.load_transformations import load_transformations
from utils.dataset import Dataset
from utils.utils import get_dataset, create_instances, format_time
from utils.Siamese import SiameseNetwork
from utils.early_stopping import EarlyStopping
from utils.LRScheduler import LRScheduler
from utils.performance_evaluation import performance_evaluation



# Get configuration
with open("config.yml", 'r') as stream:
    params = yaml.safe_load(stream) # config.yml 파일 열고 거기 있는 설정 값들을 param에 저장 (데이터 경로, 배치 크기, 학습률 등의 하이퍼파라미터)
if params['cuda']:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# random, numpy, torch 모두 같은 시드 값을 넣어(각각의 난수 발생기 시드를 고정하여) 항상 동일한 학습 결과가 나오도록 함
random.seed(params['seed'])
torch.manual_seed(params['seed'])
torch.cuda.manual_seed(params['seed'])
# When running on the CuDNN backend, two further options must be set
torch.backends.cudnn.deterministic = True # GPU 내부 연산이 무작위로 바뀌지 않도록(deterministic) 설정 (결과를 예측 가능하게 함)
torch.backends.cudnn.benchmark = False    # 성능 튜닝을 위한 자동 벤치마크 off - 결과가 매번 다르게 나오는 것 방지
# Set a fixed value for the hash seed
os.environ["PYTHONHASHSEED"] = str(params['seed'])  # 파이썬 자체의 해시 함수도 동일한 결과를 내도록 시드 고정
torch.set_float32_matmul_precision('medium')

"""### Data Loader"""

# Retrieve dataset
df = get_dataset(params) # (utils.py line 6에 설명 있음) param의 설정에 따라 데이터셋의 이미지 경로와 클래스 라벨을 담은 df 생성
#  get_dataset(params)는 params['dat_path'] 폴더의 모든 하위 폴더를 읽고, 이미지 경로(Files)와 폴더 이름에서 가져온 레이블(Lables)로 구성된 df를 만듦
# Split to train/valid/test : 학습 스크립트는 이미지 데이터셋을 불러온 뒤 학습(train), 검증(validation), 테스트 3세트로 나눔
df_train, df_test = train_test_split(df, test_size=params['test_size'], random_state=params['seed']) # sklearn의 train_test_split() 사용해 먼저 df를 학습/test로 분할 + seed 설정(항상 같은 방식으로 분할 보장)
                                                      # 분할 비율(%) 결정: '~ size'    # 결과 동일하게 재현
df_train, df_valid = train_test_split(df_train, test_size=params['valid_size'], random_state=params['seed']) # 학습 세트를 다시 학습/검증으로 분할 + seed 설정(항상 같은 방식으로 분할 보장)

# Create positive/negative instances
# 이미지셋을 나눈 뒤 Siamese 학습을 위한 이미지 쌍 구성 (create instances: utils.py line 43)
# df_train에서 데이터를 가져오고, 쌍을 몇 번 만들지는 number_of_iterations 값에 따름
# 학습 데이터에는 항상 두 이미지와, 그 이미지가 같은 클래스인지 여부(0 or 1)를 포함
train_dataset = create_instances(df=df_train, # 모델 학습용 쌍
                                 number_of_iterations=params['number_of_iterations'])
valid_dataset = create_instances(df=df_valid, # 하이퍼파라미터 튜닝 및 조기 종료 판단용 쌍
                                 number_of_iterations=params['number_of_iterations'])
test_dataset = create_instances(df=df_test, # 최종 평가용 쌍
                                number_of_iterations=params['number_of_iterations'])
# 최종 출력 형태: 리스트 [img path 1, img path 2, label]

# Get training/testing image transformations
train_tfms, test_tfms = load_transformations(params)
# load_transformations.py 안에 전처리 정의 (resize, 텐서화, 정규화..)


# Create loaders
# 학습 데이터 불러올 때 사용할 DataLoader 생성
            # 데이터셋을 불러와 배치 단위로 처리
train_dl = DataLoader(dataset = Dataset(data=train_dataset, tfms=train_tfms),
                      # 이미지 쌍과 라벨 목록이 준비되면 torch의 사용자 정의 Dataset 클래스(dataset.py)로 데이터를 불러옴
                      batch_size  = params['hyperparameters']['batch_size'],
                      shuffle     = True,
                      num_workers = params['hyperparameters']['num_workers'],
                      pin_memory  = True)


valid_dl = DataLoader(dataset = Dataset(data=valid_dataset, tfms=test_tfms),
                      batch_size  = params['hyperparameters']['batch_size'],
                      shuffle     = False, #False
                      num_workers = params['hyperparameters']['num_workers'],
                      pin_memory  = True)

test_dl = DataLoader(dataset = Dataset(data=test_dataset, tfms=test_tfms),
                      batch_size  = params['hyperparameters']['batch_size'],
                      shuffle     = False, # False
                      num_workers = params['hyperparameters']['num_workers'],
                      pin_memory  = True)
'''
                     Dataset 클래스 인스턴스를 DataLoader에 넣어서 배치 단위로 자동 로딩
                     batch_size: 한 번에 불러올 이미지 쌍 개수 (보통 32 or 64)
                     shuffle = True: 학습 시 데이터 순서를 매 epoch마다 랜덤하게 -> 일반화  //  False: 검증/테스트 시에는 고정 순서로 사용
                     num_workers: 데이터를 병렬로 불러오는 프로세스 수 (클수록 빠름)
                     pin_memory=True: GPU로의 전송 속도를 높이기 위해 설정(최적화)
'''

# 학습, 검증, 테스트에 각각 몇 개의 이미지 쌍(pair)이 생성되었는지 출력
# [img1_path, img2_path, label] 구조. 총 쌍의 개수를 len()으로 확인
# p-n 각각 하나씩 만들기 때문에 개수는 짝수가 된다 + 전체 이미지 개수의 2배 정도가 된다(iterations에 따라 달라짐)
print('[INFO] Training instances: ', train_dataset.__len__())
print('[INFO] Validation instances: ', valid_dataset.__len__())
print('[INFO] Testing instances: ', test_dataset.__len__())

"""### Training"""

# Setup model
model = SiameseNetwork(backbone_model=params['backbone_model']).to(device)

# Setup optimizer
if params['hyperparameters']['optimizer'] == 'AdamW':
    optimizer = torch.optim.AdamW(model.parameters(), lr=float(params['hyperparameters']['learning_rate']))
elif params['hyperparameters']['optimizer'] == 'Adam':
    optimizer = torch.optim.Adam(model.parameters(), lr=float(params['hyperparameters']['learning_rate']))
elif params['hyperparameters']['optimizer'] == 'SGD':
    optimizer = torch.optim.SGD(model.parameters(), lr=float(params['hyperparameters']['learning_rate']))


scheduler = LRScheduler(optimizer = optimizer,
                        patience  = params['LRScheduler']['patience'],
                        min_lr    = params['LRScheduler']['min_lr'],
                        factor    = params['LRScheduler']['factor'],
                        verbose   = params['LRScheduler']['verbose'])

# Early stopping
early_stopping = EarlyStopping(patience  = params['early_stopping']['patience'],
                               min_delta = params['early_stopping']['min_delta'])

best_AUC = 0.0
history = {'train_loss': [], 'valid_loss': [],
           'train_accuracy': [], 'valid_accuracy': [],
           'train_AUC': [], 'valid_AUC': []}


for epoch in range(params['hyperparameters']['epochs']):

    t0 = time.time()

    # Activate training mode
    model.train()

    # setup loop with TQDM and dataloader
    loop = tqdm(train_dl, leave=True)
    # setup epoch's metrics
    metrics = {'losses': [], 'accuracy': [], 'AUC': []}
    for step, (img1, img2, labels) in enumerate(loop):
        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
        # initialize calculated gradients
        optimizer.zero_grad()
        # Get loss and predictions
        predictions, loss = model(img1, img2, labels)
        # Calculate performance metrics
        accuracy, AUC, _ = performance_evaluation(labels, predictions)
        # Backpropagate errors
        loss.backward()
        # Clip gradient norm
        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=params['hyperparameters']['max_norm'])
        # update parameters
        optimizer.step()
        # Add loss
        metrics['losses'].append(loss.item())
        metrics['accuracy'].append(accuracy)
        metrics['AUC'].append(AUC)
        # add stuff to progress bar in the end
        loop.set_description(f"Epoch [{epoch+1}/{params['hyperparameters']['epochs']}]")
        loop.set_postfix(loss=f"{np.mean(metrics['losses']):.3f}",
                         accuracy=f"{np.mean(metrics['accuracy']):.2f}%",
                         AUC=f"{np.mean(metrics['AUC']):.3f}")

    # Calculate test loss/accuracy/AUC
    train_loss = np.mean(metrics['losses'])
    train_accuracy = np.mean(metrics['accuracy'])
    train_AUC = np.mean(metrics['AUC'])


    model.eval()
    ConfusionMatrix = np.array([[0,0],[0,0]]) # LIVIERIS
    # setup loop with TQDM and dataloader
    loop = tqdm(valid_dl, leave=True)
    # setup epoch's metrics
    metrics = {'losses': [], 'accuracy': [], 'AUC': []}
    for step, (img1, img2, labels) in enumerate(loop):
        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
        # Get loss & predictions
        predictions, loss = model(img1, img2, labels)
        # Calculate performance metrics
        accuracy, AUC, CM = performance_evaluation(labels, predictions)
        ConfusionMatrix+=CM
        # Add loss/accuracy/AUC
        metrics['losses'].append(loss.item())
        metrics['accuracy'].append(accuracy)
        metrics['AUC'].append(AUC)


        # add stuff to progress bar in the end
        loop.set_description(f"Epoch [{epoch+1}/{params['hyperparameters']['epochs']}]")
        loop.set_postfix(loss=f"{np.mean(metrics['losses']):.3f}",
                         accuracy=f"{np.mean(metrics['accuracy']):.2f}%",
                         AUC=f"{np.mean(metrics['AUC']):.3f}")
    print(ConfusionMatrix) # LIVIERIS
    # Calculate test loss/MSE
    valid_loss = np.mean(metrics['losses'])
    valid_accuracy = np.mean(metrics['accuracy'])
    valid_AUC = np.mean(metrics['AUC'])

    # Elapsed time per epoch
    elapsed = format_time(time.time() - t0)


    # Store performance
    history['train_loss'].append(train_loss)
    history['valid_loss'].append(valid_loss)
    history['train_accuracy'].append(train_accuracy)
    history['valid_accuracy'].append(valid_accuracy)
    history['train_AUC'].append(train_AUC)
    history['valid_AUC'].append(valid_AUC)

    # Update best model
    if valid_AUC > best_AUC:
        print('[INFO] Model saved')
        if (not os.path.exists(params['checkpoints_path'])):
            os.mkdir(params['checkpoints_path'], exist_ok=True)
        torch.save(model, os.path.join(params['checkpoints_path'], "model.pth"))
        best_AUC = valid_AUC

    # Learning rate scheduler
    scheduler(valid_AUC)

    # Early Stopping
    if early_stopping(valid_AUC): break

import pandas as pd
import matplotlib.pyplot as plt

df_results = pd.DataFrame.from_dict(history)

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))
df_results[['train_accuracy','valid_accuracy']].plot(ax=ax[0], marker='o')
df_results[['train_loss','valid_loss']].plot(ax=ax[1], marker='o')
ax[0].legend(frameon=False, fontsize=12);
ax[1].legend(frameon=False, fontsize=12);

"""### Evaluation"""

# Load optimized model
model = torch.load(params['checkpoints_path'] + '/model.pth')
model.eval()

# setup loop with TQDM and dataloader
loop = tqdm(test_dl, leave=True)
# setup epoch's metrics
metrics = {'losses': [], 'accuracy': [], 'AUC': []}
for step, (img1, img2, labels) in enumerate(loop):
    img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
    # Get loss & predictions
    predictions, loss = model(img1, img2, labels)
    # Calculate performance metrics
    accuracy, AUC, _ = performance_evaluation(labels, predictions)
    # Add loss/accuracy/AUC
    metrics['losses'].append(loss.item())
    metrics['accuracy'].append(accuracy)
    metrics['AUC'].append(AUC)


    # add stuff to progress bar in the end
    loop.set_description("Testing")
    loop.set_postfix(loss=f"{np.mean(metrics['losses']):.3f}",
                        accuracy=f"{np.mean(metrics['accuracy']):.2f}%",
                        AUC=f"{np.mean(metrics['AUC']):.3f}")


print(f"[INFO] Loss: {np.mean(metrics['losses']):.3f}")
print(f"[INFO] AUC: {np.mean(metrics['AUC']):.3f}")
print(f"[INFO] Accuracy: {np.mean(metrics['accuracy']):.2f}%")