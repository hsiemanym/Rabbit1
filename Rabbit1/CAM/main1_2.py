# GPU ì§€ì • ë° ê²½ë¡œ ì„¤ì •
import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # GPU 1ë²ˆ ì‚¬ìš©

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))  # sys.pathì— ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸ ê²½ë¡œ ì„¤ì •

import torch
import random
import numpy as np
# 1. Random seed ê³ ì •
seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.cuda.manual_seed_all(seed)

# 2. CUDNN ë¹„ê²°ì •ì„± ë¹„í™œì„±í™”
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (pytorch, ë°ì´í„° ì²˜ë¦¬ ë“±)
import yaml  # í™˜ê²½ì„¤ì •
import argparse
import clip

from torchvision import transforms  # ì´ë¯¸ì§€ ë³€í™˜
from PIL import Image, ImageDraw, ImageFont
import torch.nn.functional as F
from sklearn.metrics.pairwise import cosine_similarity

# Rabbit1 ëª¨ë¸ ë° ìœ í‹¸ ëª¨ë“ˆ import
from models.backbone import SimSiamBackbone  # ResNet-50 ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ë°±ë³¸ í´ë˜ìŠ¤
from features.embeddings import compute_embedding  # ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ë°±ë³¸ ëª¨ë¸ì˜ ì„ë² ë”© ì¶œë ¥ì„ ì–»ëŠ” í•¨ìˆ˜
from features.generic_feature_bank import build_gfb
from models.gradcam import GradCAM
from utils.similarity_utils1_2 import generate_patch_based_target
from utils.image_utils import (
    load_and_preprocess_image,  # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    overlay_heatmap,
    assemble_2x2_grid,
    save_image
)



# --------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------


# main.py ì„¤ì • ë¡œë“œ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
def load_config():
    with open("config.yml", "r") as f:
        return yaml.safe_load(f)


def extract_reference_embeddings(model, config, transform):
    # main.py ì°¸ì¡°(reference) ì´ë¯¸ì§€ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
    image_dir = config['data']['reference_dir']  # e.g., "data/rabbits" ì°¸ì¡° ì´ë¯¸ì§€ í´ë” ì§€ì •
    save_path = config['features']['embedding_cache']
    # e.g., "features/embeddings.pth" ì„ë² ë”© ìºì‹œ ë¡œë“œ (í‚¤=íŒŒì¼ëª…, ê°’=í•´ë‹¹ ì´ë¯¸ì§€ì˜ 256ì°¨ì› ì„ë² ë”© í…ì„œ)
    # extract_features.pyë¥¼ í†µí•´ ëª¨ë“  ê¸°ì¤€ ì´ë¯¸ì§€ì˜ ì„ë² ë”©ì„ í•œ ë²ˆì— ê³„ì‚°/ì €ì¥í•´ë‘ê³  í™œìš© - ë§¤ í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ê¸°ì¤€ ì´ë¯¸ì§€ë¥¼ ì¼ì¼ì´ ëª¨ë¸ì— ë„£ì§€ ì•Šê³  ë°”ë¡œ ì„ë² ë”© ë¹„êµ (ì†ë„ up)

    embeddings = {}
    for fname in sorted(os.listdir(image_dir)):
        if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):
            continue
        path = os.path.join(image_dir, fname)
        image = load_and_preprocess_image(path, transform).unsqueeze(0).to(device)
        emb = compute_embedding(model, image)
        embeddings[fname] = emb.squeeze(0).cpu()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torch.save(embeddings, save_path)
    print(f"[âœ“] Saved reference embeddings to {save_path}")
    return embeddings


def retrieve_top1_clipfiltered(test_img_path, model, reference_dict, config, transform):
    """
    SimSiam cosine similarity top-5 â†’ ê·¸ ì¤‘ CLIPScore ìµœê³  í›„ë³´ ë°˜í™˜
    """

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    clip_model, preprocess = clip.load("ViT-B/32", device=device)
    clip_model.eval()

    names = list(reference_dict.keys())
    mat = torch.stack([reference_dict[n] for n in names])
    test_img = load_and_preprocess_image(test_img_path, transform).unsqueeze(0).to(device)
    test_emb = compute_embedding(model, test_img, no_grad=True)

    sims = cosine_similarity(test_emb.cpu().numpy(), mat.numpy())  # [1, N]
    idxs = sims[0].argsort()[::-1][:5]
    top5_names = [names[i] for i in idxs]

    def clip_score(img1_path, img2_path):
        image1 = preprocess(Image.open(img1_path)).unsqueeze(0).to(device)
        image2 = preprocess(Image.open(img2_path)).unsqueeze(0).to(device)
        with torch.no_grad():
            emb1 = clip_model.encode_image(image1).float()
            emb2 = clip_model.encode_image(image2).float()
            emb1 = emb1 / emb1.norm(dim=-1, keepdim=True)
            emb2 = emb2 / emb2.norm(dim=-1, keepdim=True)
        return (emb1 * emb2).sum().item()

    best_score = -1
    best_name = None
    test_img_abs = os.path.abspath(test_img_path)
    ref_dir = config['data']['reference_dir']

    for name in top5_names:
        ref_path = os.path.join(ref_dir, name)
        score = clip_score(test_img_abs, ref_path)
        if score > best_score:
            best_score = score
            best_name = name

    return best_name, best_score


def run_pipeline(test_img_path, gfb_option='A'):
    config = load_config()

    # --------------------------
    # 1. Model & Transform
    # --------------------------
    model = SimSiamBackbone(pretrained=True).to(device)  # ì‚¬ì „í•™ìŠµëœ SimSiam ë°±ë³¸ ëª¨ë¸ ì´ˆê¸°í™”
    '''
    Grad_CAM_Siamese ì›ë³¸ì˜ ì‹œì•”ìŒ ë„¤íŠ¸ì›Œí¬ì—ì„œ íŒŒìƒë˜ì—ˆì§€ë§Œ 
        (ì›ë³¸ ëª¨ë¸ì˜ SiameseNetworkëŠ” ResNet-50 ê¸°ë°˜ ì–‘ë¶„ë§ìœ¼ë¡œ ë‘ ì…ë ¥ ì´ë¯¸ì§€ ê°ê°ì„ Conv í†µê³¼ 
        -> FC í†µí•´ 2ì°¨ì› ì¶œë ¥(ê±°ë¦¬ ë° ìœ ì‚¬ë„ í™•ë¥ )ì„ ì‚°ì¶œ
        contrastive Loss í•™ìŠµì„ ìœ„í•´ outputì´ sigmoidë¡œ "ê°™ì€/ë‹¤ë¥¸ í´ë˜ìŠ¤" í™•ë¥ ì„ ë‚´ëŠ” êµ¬ì¡°ì˜€ìŒ)

    ë‘ ì´ë¯¸ì§€ ì…ë ¥ ëŒ€ì‚° ë‹¨ì¼ ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œìš©ìœ¼ë¡œ ì‚¬ìš©
    (ì›ë³¸ ëª¨ë¸ì€ ë‘ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ê±°ë¦¬(Dw)ì™€ ì‹œë°€ëŸ¬ë¦¬í‹°(sigmoid ì¶œë ¥)ë¥¼ ë‚´ë†“ì•˜ìœ¼ë‚˜,
    Rabbit1ì—ì„œëŠ” ë§ˆì§€ë§‰ ì‹œë°€ëŸ¬ë¦¬í‹° ì˜ˆì¸¡ ë ˆì´ì–´ë¥¼ ì œì™¸í•˜ê³  256ì°¨ì› ì„ë² ë”© ì¶”ì¶œê¹Œì§€ë§Œ ì‚¬ìš© = ëª¨ë¸ì„ íŠ¹ì§• ì¶”ì¶œê¸°(feature extractor)ë¡œ í™œìš©) 
        (Rabbit1ì—ì„œëŠ” ëª¨ë“  ì´ë¯¸ì§€ê°€ í•œ í´ë˜ìŠ¤(í† ë¼)ë¡œ, ëŒ€ì¡°í•™ìŠµì´ ë¶ˆí•„ìš”
        FC ì¶œë ¥ì¸µê³¼ contrastive ì†ì‹¤ ë¶€ë¶„ì€ ì œê±°í•˜ê³  256ì°¨ì› ì„ë² ë”©ë§Œ ì¬ì‚¬ìš© - ë‘ ì´ë¯¸ì§€ì˜ ì„ë² ë”© ì‚¬ì´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì „í™˜)
    -> ëª¨ë¸ forwardë¥¼ í•œ ì´ë¯¸ì§€ì”© í˜¸ì¶œ - ê²°ê³¼ ì„ë² ë”©ì„ ê°€ì§€ê³  ë³„ë„ë¡œ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨
    '''
    model.eval()  # í‰ê°€ëª¨ë“œë¡œ ì „í™˜

    transform = transforms.Compose([
        transforms.Resize(config['image']['size']),
        transforms.ToTensor(),
        transforms.Normalize(mean=config['image']['normalization']['mean'],
                             std=config['image']['normalization']['std'])
    ])


    # --------------------------
    # 2. Extract embeddings
    # --------------------------

    reference_embeddings = extract_reference_embeddings(model, config, transform)

    # --------------------------
    # 3. Build GFB
    # --------------------------
    gfb_path = config['features']['generic_bank']
    patch_file = config['features']['patch_file']
    from scripts.extract_patches import extract_all_patches
    if not os.path.exists(patch_file):
        print(f"[!] Patch file not found: {patch_file}")
        print(f"[â†’] Extracting patches using conv5 feature maps...")
        extract_all_patches(model, config, transform, device)
    gfb_tensor = build_gfb(patch_file, save_path=gfb_path, option=gfb_option)
    gfb_tensor = gfb_tensor.to(device)

    # --------------------------
    # 4. Retrieve Top-1
    # --------------------------
    img_test = load_and_preprocess_image(test_img_path, transform).unsqueeze(0).to(device)
    emb_test = compute_embedding(model, img_test, no_grad=True)  # retrieval only
    top1_name, sim_score = retrieve_top1_clipfiltered(test_img_path, model, reference_embeddings, config, transform)

    top1_path = os.path.join(config['data']['reference_dir'], top1_name)
    img_ref = load_and_preprocess_image(top1_path, transform).unsqueeze(0).to(device)
    emb_ref = compute_embedding(model, img_ref, no_grad=True)

    print(f"[âœ“] Top-1 for {os.path.basename(test_img_path)} â†’ {top1_name}  ({sim_score:.4f})")

    # --------------------------
    # 5. Grad-CAM + GFB ì‹œê°í™”
    # --------------------------
    gradcam = GradCAM(model, ['encoder.7'])



    def get_masked_cam(query_tensor, target_tensor, fmap):
        # 1. backbone â†’ feature map â†’ projection
        feat = model.forward_backbone(query_tensor)  # [1, 2048, H, W]
        pooled = F.adaptive_avg_pool2d(feat, (1, 1))  # [1, 2048, 1, 1]
        pooled = pooled.view(pooled.size(0), -1)  # [1, 2048]
        pooled.requires_grad_(True)

        z1 = model.projector(pooled)  # [1, 256]
        z2 = target_tensor.detach()  # [1, 256] projection-based target

        # 2. cosine similarity
        sim = F.cosine_similarity(z1, z2, dim=1)  # [1]
        target_score = sim.sum()

        # 3. Grad-CAM
        cam = gradcam.generate(query_tensor, target_score)[0]

        # 4. GFB ë§ˆìŠ¤í‚¹
        return filter_with_gfb(cam, fmap, gfb_tensor, threshold = config['gfb']['threshold'])

    # Grad-CAM ë§µ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    gradcam = GradCAM(model, ['encoder.7'])

    z_test = compute_embedding(model, img_test, no_grad=False)
    z_ref = compute_embedding(model, img_ref, no_grad=False)

    raw_test = Image.open(test_img_path).convert('RGB').resize(config['image']['size'])
    raw_ref = Image.open(top1_path).convert('RGB').resize(config['image']['size'])

    fmap_test = model.get_feature_map(img_test).squeeze(0)
    fmap_ref = model.get_feature_map(img_ref).squeeze(0)

    # ---------- 1. Factual (No GFB) Grad-CAM Only ---------- #

    # [Test â†’ Ref]
    feat_test = model.forward_backbone(img_test)  # [1, 2048, H, W]
    pooled_test = F.adaptive_avg_pool2d(feat_test, (1, 1)).view(1, -1).requires_grad_()  # [1, 2048] + grad
    z_test_proj = model.projector(pooled_test)  # [1, 256]

    feat_ref = model.forward_backbone(img_ref)  # [1, 2048, H, W]
    pooled_ref = F.adaptive_avg_pool2d(feat_ref, (1, 1)).view(1, -1).detach()  # [1, 2048] + no grad
    z_ref_proj = model.projector(pooled_ref)  # [1, 256]

    score_test_fg = F.cosine_similarity(z_test_proj, z_ref_proj, dim=1).sum()
    cam0_test = gradcam.generate(img_test, score_test_fg)[0]

    # [Ref â†’ Test]
    # ---------- Ref â†’ Test (Factual, No GFB) ---------- #
    feat_ref = model.forward_backbone(img_ref)
    feat_ref.requires_grad_()  # ğŸ”¥ ì—­ì „íŒŒ ì—°ê²°
    feat_ref.retain_grad()  # ğŸ”¥ .gradê°€ Noneì´ ë˜ì§€ ì•Šê²Œ

    pooled_ref = F.adaptive_avg_pool2d(feat_ref, (1, 1)).view(1, -1)
    z_ref_proj = model.projector(pooled_ref)

    feat_test = model.forward_backbone(img_test)
    pooled_test = F.adaptive_avg_pool2d(feat_test, (1, 1)).view(1, -1).detach()
    z_test_proj = model.projector(pooled_test)

    score = F.cosine_similarity(z_ref_proj, z_test_proj, dim=1).sum()
    score.backward(retain_graph=True)

    # ë””ë²„ê¹…
    print(f"[CHECK] feat_ref.grad mean: {feat_ref.grad.mean().item():.6f}")

    # Grad-CAM ì‹¤í–‰
    cam0_ref = gradcam.generate_from_features(feat_ref, feat_ref.grad, img_ref)

    # Visualization
    vis0 = overlay_heatmap(raw_test, cam0_test)
    vis1 = overlay_heatmap(raw_ref, cam0_ref)

    # ---------- 2. factual (GFB í•„í„° ì ìš©) ---------- #
    emb_ref_proj = model.projector(emb_ref.to(device))  # [1, 256]
    cam1 = get_masked_cam(img_test, emb_ref_proj, fmap_test)
    emb_test_proj = model.projector(emb_test.to(device))  # [1, 256]
    cam2 = get_masked_cam(img_ref, emb_test_proj, fmap_ref)
    vis2 = overlay_heatmap(raw_test, cam1)
    vis3 = overlay_heatmap(raw_ref, cam2)

    # ---------- 3. counterfactual (patch-aware Grad-CAM) ---------- #
    from utils.similarity_utils1_2 import generate_patch_based_target

    # 1. patch-aware target weights
    target_weights = generate_patch_based_target(
        fmap_test, fmap_ref, gfb_tensor,
        threshold=config['gfb']['threshold'],
        gfb_chunk_size=32,
        ref_chunk_size=128
    )  # [H, W]

    # 2. Get conv5 feature map from backbone
    feat_test = model.forward_backbone(img_test)  # [1, 2048, H, W]
    feat_test.retain_grad()

    # Grad-CAM targetìœ¼ë¡œ ì§ì ‘ projection featureë¥¼ ì„ íƒí•´ì„œ
    # testì—ì„œ counterfactualí•œ patch ìœ„ì¹˜ì˜ projection vector í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ scoreë¡œ ì”€
    with torch.no_grad():
        cf_score_map = target_weights
        max_y, max_x = torch.where(cf_score_map == cf_score_map.max())
        y, x = max_y[0].item(), max_x[0].item()

    # 1. Grad-CAM hook ê¸°ì¤€ feature map
    feat_test = model.forward_backbone(img_test).detach()  # [1, 2048, H, W]

    # 2. í•´ë‹¹ ìœ„ì¹˜ì˜ vector â†’ projection â†’ scalar
    patch_vector = feat_test[0, :, y, x].unsqueeze(0).requires_grad_()  # [1, 2048]
    proj_vector = model.projector(patch_vector)  # [1, 256]
    score_test_cf = proj_vector.sum()

    # 3. Grad-CAM ìˆ˜í–‰
    cam_test_cf = gradcam.generate(img_test, score_test_cf)[0]

    # 4. ref image: ê¸°ì¡´ ë°©ì‹ (ìœ ì‚¬ë„ ìŒìˆ˜)
    z_ref_cf = model.get_embedding(img_ref).requires_grad_()
    z_test_cf = model.get_embedding(img_test).detach()
    score_ref_cf = -F.cosine_similarity(z_ref_cf, z_test_cf, dim=1).sum()
    cam_ref_cf = gradcam.generate(img_ref, score_ref_cf)[0]

    # 5. counterfactual ë§ˆìŠ¤í¬ (GFB ê¸°ë°˜ filtering)
    from utils.similarity_utils import compute_counterfactual_score
    cf_mask_test = compute_counterfactual_score(fmap_test, fmap_ref, gfb_tensor, threshold=config['gfb']['threshold'])
    cf_mask_ref = compute_counterfactual_score(fmap_ref, fmap_test, gfb_tensor, threshold=config['gfb']['threshold'])

    cf_mask_test_up = F.interpolate(cf_mask_test.unsqueeze(0).unsqueeze(0), size=cam_test_cf.shape, mode='bilinear',
                                    align_corners=False).squeeze()
    cf_mask_ref_up = F.interpolate(cf_mask_ref.unsqueeze(0).unsqueeze(0), size=cam_ref_cf.shape, mode='bilinear',
                                   align_corners=False).squeeze()

    # 6. masking & visualization
    cam3 = cam_test_cf * cf_mask_test_up.cpu().numpy()
    cam4 = cam_ref_cf * cf_mask_ref_up.cpu().numpy()
    vis4 = overlay_heatmap(raw_test, cam3)
    vis5 = overlay_heatmap(raw_ref, cam4)

    labels = [
        "Test - Factual (No GFB)", "Ref - Factual (No GFB)",
        "Test - Factual (GFB)", "Ref - Factual (GFB)",
        "Test - Counterfactual", "Ref - Counterfactual"
    ]

    grid = assemble_2x2_grid(
        [vis0, vis1, vis2, vis3, vis4, vis5],
        labels=labels,
        rows=3, cols=2)

    os.makedirs('output', exist_ok=True)
    fname = os.path.splitext(os.path.basename(test_img_path))[0]
    save_image(grid, f'output/main1_2_{fname}_explanation_full.png')
    print(f"[âœ“] Saved 2x3 explanation to output/main1_2_{fname}_explanation_full.png")


def generate_gradcam_heatmap(model, gradcam, input_tensor, target_tensor, emphasize=True):
    """
    Compute Grad-CAM heatmap given query and target tensor.
    Both must have gradient enabled (i.e., from get_embedding, not no_grad).

    If emphasize=True, apply softmax-like nonlinear transformation to boost salient regions.
    """
    # 1. Cosine similarity â†’ scalar score
    sim = F.cosine_similarity(input_tensor, target_tensor, dim=1)  # [1]
    score = sim.sum()  # scalar

    # 2. Grad-CAM heatmap
    cam = gradcam.generate(input_tensor=input_tensor, target_score=score)[0]  # numpy [H, W]

    # 3. Emphasize salient regions using exp
    if emphasize:
        import numpy as np
        cam = np.clip(cam, 0, None)  # ìŒìˆ˜ ì œê±°
        cam = np.exp(3 * cam)  # 3ë°° ê°•í™” í›„ exp
        cam = cam / (np.max(cam) + 1e-8)  # ì •ê·œí™”

    return cam


def filter_with_gfb(heatmap, fmap, gfb, threshold=None):
    if threshold is None:
        config = load_config()
        threshold = config['gfb']['threshold']

    C, H, W = fmap.shape
    mask = torch.zeros((H, W), dtype=torch.float32, device=fmap.device)

    for y in range(H):
        for x in range(W):
            patch = fmap[:, y, x]
            '''
            sims = F.cosine_similarity(patch.unsqueeze(0), gfb)
            if sims.max() < threshold:
                mask[y, x] = 1.0
            '''
            # ----------------------------------
            sims = F.cosine_similarity(patch.unsqueeze(0), gfb)  # [N]
            topk = torch.topk(sims, k=5).values  # ìƒìœ„ 5ê°œ ìœ ì‚¬ë„
            # if topk.mean() < threshold:
            ##################################
            if topk.mean() < threshold and topk.max() < threshold + 0.05:
            #################################
                mask[y, x] = 1.0
            # ----------------------------------

    #  ì—…ìƒ˜í”Œë§ (heatmap í¬ê¸°ì™€ ì¼ì¹˜ì‹œí‚¤ê¸°)
    mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0), size=heatmap.shape, mode='bilinear',
                         align_corners=False)
    mask = mask.squeeze().cpu().numpy()

    return heatmap * mask




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--test_img", type=str, required=True, help="Path to test image")
    parser.add_argument("--gfb_option", type=str, default='A', choices=['A', 'B'], help="GFB ìƒì„± ì˜µì…˜")
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    run_pipeline(args.test_img, args.gfb_option)